{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JgLiCCeCs7im"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Step 1: Import All Required Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 2: Load Dataset and Prepare Dataloaders\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load Oxford-IIIT Pet dataset\n",
        "data = datasets.OxfordIIITPet(\n",
        "    root=\"./data\",\n",
        "    download=True,\n",
        "    transform=transform,\n",
        "    target_types=\"category\"\n",
        ")\n",
        "\n",
        "# Split into train and validation sets\n",
        "train_size = int(0.8 * len(data))\n",
        "val_size = len(data) - train_size\n",
        "train_data, val_data = random_split(data, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfzO23bBtJms",
        "outputId": "83259b4f-ac78-4b58-ea46-bf1ef4a554c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 792M/792M [00:20<00:00, 38.5MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.2M/19.2M [00:01<00:00, 15.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f61ecb6",
        "outputId": "296849bd-2b4d-40be-f2eb-101ce819514e"
      },
      "source": [
        "# ðŸ“Œ Step 3: Define the CNN Model\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 37)  # 37 pet categories\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 4: Loss and Optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "CnZeNLcJtVLu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 5: Train the Model\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ7Zr8hnvO_2",
        "outputId": "707c0509-11a2-4f17-b86e-92c9e425dbd4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.6507\n",
            "Epoch 2, Loss: 0.7474\n",
            "Epoch 3, Loss: 0.4740\n",
            "Epoch 4, Loss: 0.3327\n",
            "Epoch 5, Loss: 0.2414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 6: Evaluate the Model\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bn7WJwKyRD3",
        "outputId": "0e945c71-187a-46c0-a2a7-ffdfcc6e9c78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.16      0.25        19\n",
            "           1       0.50      0.35      0.41        20\n",
            "           2       0.50      0.07      0.12        15\n",
            "           3       0.58      0.62      0.60        24\n",
            "           4       0.21      0.67      0.32        18\n",
            "           5       1.00      0.18      0.31        22\n",
            "           6       0.53      0.50      0.51        18\n",
            "           7       0.57      0.57      0.57        14\n",
            "           8       0.36      0.74      0.49        23\n",
            "           9       0.29      0.29      0.29        24\n",
            "          10       0.71      0.50      0.59        20\n",
            "          11       0.50      0.47      0.48        15\n",
            "          12       1.00      0.09      0.17        22\n",
            "          13       0.00      0.00      0.00        20\n",
            "          14       0.61      0.71      0.65        24\n",
            "          15       0.78      0.37      0.50        19\n",
            "          16       1.00      0.20      0.33        15\n",
            "          17       0.67      0.71      0.69        17\n",
            "          18       0.23      1.00      0.37        18\n",
            "          19       0.30      0.18      0.22        17\n",
            "          20       0.90      0.56      0.69        16\n",
            "          21       1.00      0.21      0.34        24\n",
            "          22       0.60      0.12      0.19        26\n",
            "          23       0.82      0.61      0.70        23\n",
            "          24       0.89      0.50      0.64        16\n",
            "          25       0.94      0.65      0.77        23\n",
            "          26       0.48      0.53      0.50        19\n",
            "          27       0.24      0.86      0.38        22\n",
            "          28       0.60      0.71      0.65        21\n",
            "          29       0.81      0.74      0.77        23\n",
            "          30       0.64      0.37      0.47        19\n",
            "          31       0.59      0.57      0.58        23\n",
            "          32       0.70      0.86      0.78        22\n",
            "          33       0.64      0.89      0.74        18\n",
            "          34       0.33      0.56      0.42        18\n",
            "          35       0.88      0.58      0.70        24\n",
            "          36       0.91      0.67      0.77        15\n",
            "\n",
            "    accuracy                           0.50       736\n",
            "   macro avg       0.62      0.50      0.49       736\n",
            "weighted avg       0.62      0.50      0.49       736\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}